# step_log(MonthlyRate, base = 10) %>%
prep()
prep_training_tbl <- recipe(Attrition ~ .,
data = employee_training) %>%
# Remove collinear predictors (omit outcomes with -all_outcomes() if numeric)
step_corr(all_numeric(), threshold = 0.9) %>%
# Normalise - also try step_normalize()
step_center(all_numeric()) %>%
step_scale(all_numeric()) %>%
# Add log transformation step for variable that are asymmetric
# step_log(MonthlyRate, base = 10) %>%
prep() %>% bake(new_data = employee_training)
# * Final recipe ----
prep_training_tbl <- recipe(Attrition ~ .,
data = attrition) %>%
# Remove collinear predictors (omit outcomes with -all_outcomes() if numeric)
step_corr(all_numeric(), threshold = 0.9) %>%
# Normalise - also try step_normalize()
step_center(all_numeric()) %>%
step_scale(all_numeric()) %>%
# Add log transformation step for variable that are asymmetric
# step_log(MonthlyRate, base = 10) %>%
prep() %>% bake(new_data = employee_training)
# * Final recipe ----
prep_training_tbl <- recipe(Attrition ~ .,
data = attrition) %>%
# Remove collinear predictors (omit outcomes with -all_outcomes() if numeric)
step_corr(all_numeric(), threshold = 0.9) %>%
# Normalise - also try step_normalize()
step_center(all_numeric()) %>%
step_scale(all_numeric()) %>%
# Add log transformation step for variable that are asymmetric
# step_log(MonthlyRate, base = 10) %>%
prep() %>% bake(new_data = attrition)
prep_training_tbl_split <- initial_split(prep_training_tbl,
prop = 0.75,
strata = Attrition)
prep_logistic_fit <- logistic_model %>%
last_fit(Attrition ~ ., split = prep_training_tbl_split)
# Collect predictions and view results
prep_predictions_df <- prep_logistic_fit %>%
collect_predictions()
prep_predictions_df %>%
roc_curve(truth = Attrition, .pred_No) %>%
autoplot()
# Calculate metrics
last_fit_metrics(prep_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# Calculate metrics
last_fit_metrics(predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# * Final recipe ----
prep_training_tbl <- recipe(Attrition ~ .,
data = attrition) %>%
# Remove collinear predictors (omit outcomes with -all_outcomes() if numeric)
step_corr(all_numeric(), threshold = 0.9) %>%
# Normalise - also try step_normalize()
# step_center(all_numeric()) %>%
# step_scale(all_numeric()) %>%
# Add log transformation step for variable that are asymmetric
# step_log(MonthlyRate, base = 10) %>%
prep() %>% bake(new_data = attrition)
prep_training_tbl_split <- initial_split(prep_training_tbl,
prop = 0.75,
strata = Attrition)
prep_logistic_fit <- logistic_model %>%
last_fit(Attrition ~ ., split = prep_training_tbl_split)
prep_predictions_df %>%
roc_curve(truth = Attrition, .pred_No) %>%
autoplot()
# Collect predictions and view results
prep_predictions_df <- prep_logistic_fit %>%
collect_predictions()
# Calculate metrics
last_fit_metrics(prep_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# * Final recipe ----
prep_training_tbl <- recipe(Attrition ~ .,
data = attrition) %>%
# Remove collinear predictors (omit outcomes with -all_outcomes() if numeric)
# step_corr(all_numeric(), threshold = 0.9) %>%
# Normalise - also try step_normalize()
# step_center(all_numeric()) %>%
# step_scale(all_numeric()) %>%
# Add log transformation step for variable that are asymmetric
# step_log(MonthlyRate, base = 10) %>%
prep() %>% bake(new_data = attrition)
prep_training_tbl_split <- initial_split(prep_training_tbl,
prop = 0.75,
strata = Attrition)
prep_logistic_fit <- logistic_model %>%
last_fit(Attrition ~ ., split = prep_training_tbl_split)
# Collect predictions and view results
prep_predictions_df <- prep_logistic_fit %>%
collect_predictions()
prep_predictions_df %>%
roc_curve(truth = Attrition, .pred_No) %>%
autoplot()
# Calculate metrics
last_fit_metrics(prep_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# * Final recipe ----
prep_training_tbl <- recipe(Attrition ~ .,
data = attrition) %>%
# Remove collinear predictors (omit outcomes with -all_outcomes() if numeric)
step_corr(all_numeric(), threshold = 0.9) %>%
# Normalise - also try step_normalize()
step_normalize(all_numeric()) %>%
# step_center(all_numeric()) %>%
# step_scale(all_numeric()) %>%
# Add log transformation step for variable that are asymmetric
# step_log(MonthlyRate, base = 10) %>%
prep() %>% bake(new_data = attrition)
prep_training_tbl_split <- initial_split(prep_training_tbl,
prop = 0.75,
strata = Attrition)
prep_logistic_fit <- logistic_model %>%
last_fit(Attrition ~ ., split = prep_training_tbl_split)
# Collect predictions and view results
prep_predictions_df <- prep_logistic_fit %>%
collect_predictions()
prep_predictions_df %>%
roc_curve(truth = Attrition, .pred_No) %>%
autoplot()
# Calculate metrics
last_fit_metrics(prep_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# Calculate metrics
last_fit_metrics(predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# * Final recipe ----
prep_tbl <- recipe(Attrition ~ .,
data = attrition) %>%
# Remove collinear predictors (omit outcomes with -all_outcomes() if numeric)
step_corr(all_numeric(), threshold = 0.9) %>%
# Normalise - also try step_normalize()
step_normalize(all_numeric()) %>%
# step_center(all_numeric()) %>%
# step_scale(all_numeric()) %>%
# Add log transformation step for variable that are asymmetric
# step_log(MonthlyRate, base = 10) %>%
prep() %>% bake(new_data = attrition)
prep_tbl_split <- initial_split(prep_training_tbl,
prop = 0.75,
strata = Attrition)
prep_logistic_fit <- logistic_model %>%
last_fit(Attrition ~ ., split = prep_tbl_split)
prep_predictions_df %>%
roc_curve(truth = Attrition, .pred_No) %>%
autoplot()
# Collect predictions and view results
prep_predictions_df <- prep_logistic_fit %>%
collect_predictions()
# Calculate metrics
last_fit_metrics(prep_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
employee_training
# 8.0 CROSS VALIDATION ----
#
# Create cross validation folds
set.seed(290)
employee_folds <- vfold_cv(employee_training, v = 5,
strata = Attrition)
employee_folds
# Create custom metrics function
employee_metrics <- metric_set(roc_auc, sens, spec)
employee_dt_wkfl <- workflow()
dt_model <- decision_tree() %>%
# Specify the engine
set_engine('rpart') %>%
# Specify the mode
set_mode('classification')
# Build feature engineering pipeline
employee_recipe <- recipe(Attrition ~ .,
data = employee_training) %>%
# Correlation filter
step_corr(all_numeric(), threshold = 0.85) %>%
# Normalize numeric predictors
step_normalize(all_numeric()) %>%
# Create dummy variables
step_dummy(all_nominal(), -all_outcomes())
# Create a workflow
employee_dt_wkfl <- workflow() %>%
# Include the model object
add_model(dt_model) %>%
# Include the recipe object
add_recipe(employee_recipe)
# 8.0 CROSS VALIDATION ----
#
# Create cross validation folds
set.seed(290)
employee_folds <- vfold_cv(employee_training, v = 5,
strata = Attrition)
# Create custom metrics function
employee_metrics <- metric_set(roc_auc, sens, spec)
dt_model <- decision_tree() %>%
# Specify the engine
set_engine('rpart') %>%
# Specify the mode
set_mode('classification')
# Build feature engineering pipeline
employee_recipe <- recipe(Attrition ~ .,
data = employee_training) %>%
# Correlation filter
step_corr(all_numeric(), threshold = 0.85) %>%
# Normalize numeric predictors
step_normalize(all_numeric()) %>%
# Create dummy variables
step_dummy(all_nominal(), -all_outcomes())
# Create a workflow
employee_dt_wkfl <- workflow() %>%
# Include the model object
add_model(dt_model) %>%
# Include the recipe object
add_recipe(employee_recipe)
# Fit resamples
employee_dt_rs <- employee_dt_wkfl %>%
fit_resamples(resamples = employee_folds,
metrics = employee_metrics)
# View performance metrics
employee_dt_rs %>%
collect_metrics()
# Calculate metrics
last_fit_metrics(prep_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# Create custom metrics function
employee_metrics <- metric_set(accuracy, sens, spec, roc_auc)
# Calculate metrics
last_fit_metrics(predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# 8.0 CROSS VALIDATION ----
#
# Create cross validation folds
set.seed(290)
employee_folds <- vfold_cv(employee_training, v = 5,
strata = Attrition)
# Create custom metrics function
employee_metrics <- metric_set(accuracy, sens, spec, roc_auc)
dt_model <- decision_tree() %>%
# Specify the engine
set_engine('rpart') %>%
# Specify the mode
set_mode('classification')
# Build feature engineering pipeline
employee_recipe <- recipe(Attrition ~ .,
data = employee_training) %>%
# Correlation filter
step_corr(all_numeric(), threshold = 0.85) %>%
# Normalize numeric predictors
step_normalize(all_numeric()) %>%
# Create dummy variables
step_dummy(all_nominal(), -all_outcomes())
# Create a workflow
employee_dt_wkfl <- workflow() %>%
# Include the model object
add_model(dt_model) %>%
# Include the recipe object
add_recipe(employee_recipe)
# Fit resamples
employee_dt_rs <- employee_dt_wkfl %>%
fit_resamples(resamples = employee_folds,
metrics = employee_metrics)
# View performance metrics
employee_dt_rs %>%
collect_metrics()
# Calculate metrics
last_fit_metrics(prep_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
logistic_model <- logistic_reg() %>%
# Specify the engine
set_engine('glm') %>%
# Specify the mode
set_mode('classification')
# Create workflow
employee_logistic_wkfl <- workflow() %>%
# Add model
add_model(logistic_model) %>%
# Add recipe
add_recipe(employee_recipe)
# Create workflow
employee_logistic_wkfl <- workflow() %>%
# Add model
add_model(logistic_model) %>%
# Add recipe
add_recipe(employee_recipe)
# Create workflow
employee_logistic_wkfl <- workflow() %>%
# Add model
add_model(logistic_model) %>%
# Add recipe
add_recipe(employee_recipe)
# Fit resamples
employee_logistic_rs <- employee_logistic_wkfl %>%
fit_resamples(resamples = employee_folds,
metrics = employee_metrics)
# View performance metrics
employee_logistic_rs %>%
collect_metrics()
# View performance metrics
employee_dt_rs %>%
collect_metrics()
# Calculate metrics
last_fit_metrics(prep_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
?parsnip_add
?parsnip_addin
dt_model <- decision_tree() %>%
# Specify the engine
set_engine('rpart') %>%
# Specify the mode
set_mode('classification')
# * Decision Tree CV ----
#
parsnip_addin()
install.packages(c("shiny", "miniUI", "rstudioapi"))
install.packages(c("shiny", "miniUI", "rstudioapi"))
install.packages(c("shiny", "miniUI", "rstudioapi"))
install.packages(c("shiny", "miniUI", "rstudioapi"))
install.packages(c("shiny", "miniUI", "rstudioapi"))
install.packages(c("shiny", "miniUI", "rstudioapi"))
# * Decision Tree CV ----
#
parsnip_addin()
# install.packages(c("shiny", "miniUI", "rstudioapi"))
install.packages("parsnip_addin")
# * Decision Tree CV ----
#
parsnip_addin()
# install.packages(c("shiny", "miniUI", "rstudioapi"))
install.packages("parsnip_addin")
# Detailed cross validation results
dt_rs_results <- employee_dt_rs %>%
collect_metrics(summarize = FALSE)
# TIDYMODELS WORKFLOW - REGRESSION ----
#
# 1.0 LOAD LIBRARIES ----
library(tidymodels)
library(modeldata)
# Detailed cross validation results
dt_rs_results <- employee_dt_rs %>%
collect_metrics(summarize = FALSE)
dt_rs_results
# Explore model performance for decision tree
dt_rs_results %>%
group_by(.metric) %>%
summarize(min = min(.estimate),
median = median(.estimate),
max = max(.estimate))
# View performance metrics
employee_dt_rs %>%
collect_metrics()
# Detailed cross validation results
logistic_rs_results <- employee_logistic_rs %>%
collect_metrics(summarize = FALSE)
# Explore model performance for logistic regression
logistic_rs_results %>%
group_by(.metric) %>%
summarize(min = min(.estimate),
median = median(.estimate),
max = max(.estimate))
# Set tuning hyperparameters
dt_tune_model <- decision_tree(cost_complexity = tune(),
tree_depth = tune(),
min_n = tune()) %>%
# Specify engine
set_engine('rpart') %>%
# Specify mode
set_mode('classification')
# Create a tuning workflow
employee_tune_wkfl <- employee_dt_wkfl %>%
# Replace model
update_model(dt_tune_model)
employee_tune_wkfl
# * Accuracy = (TP + TN)/(TP + FP + TN + FN)
# * Selectivity = TN/(TN + FN)
# * False Positive Rate (FPR) = 1 - Selectivity (type I error)
# * Sensitivity =  TP/(TP + FP)
# * False Negative Rate (FNR) = 1 - Sensitivity (type II error)
#
# * Search parsnip models ----
# https://www.tidymodels.org/find/parsnip/
#
# 1.0 LOAD LIBRARIES ----
library(tidymodels)
library(modeldata)
shiny::runGadget(sparklyr::connection_spark_shinyapp(), viewer = .rs.embeddedViewer)
install.packages("learnr")
# Hyperparameter tuning with grid search
set.seed(214)
dt_grid <- grid_random(parameters(dt_tune_model),
size = 5)
# Hyperparameter tuning
dt_tuning <- employee_tune_wkfl %>%
tune_grid(resamples = employee_folds,
grid = dt_grid,
metrics = employee_metrics)
# View results
dt_tuning %>%
collect_metrics()
# Collect detailed tuning results
dt_tuning_results <- dt_tuning %>%
collect_metrics(summarize = FALSE)
# Explore detailed ROC AUC results for each fold
dt_tuning_results %>%
filter(.metric == "roc_auc") %>%
group_by(id) %>%
summarize(min_roc_auc = min(.estimate),
median_roc_auc = median(.estimate),
max_roc_auc = max(.estimate))
##
# Display 5 best performing models
dt_tuning %>%
show_best(metric = 'roc_auc', n = 5)
# Select based on best performance
best_dt_model <- dt_tuning %>%
# Choose the best model based on roc_auc
select_best(metric = 'roc_auc')
best_dt_model
# Finalize your workflow
final_employee_wkfl <- employee_tune_wkfl %>%
finalize_workflow(best_dt_model)
final_employee_wkfl
# Train finalized decision tree workflow
employee_final_fit <- final_employee_wkfl %>%
last_fit(split = employee_split)
# View performance metrics
employee_final_fit %>%
collect_metrics()
# Create an ROC curve
employee_final_fit %>%
# Collect predictions
collect_predictions()
# Create an ROC curve
employee_final_fit %>%
# Collect predictions
collect_predictions() %>%
# Calculate ROC curve metrics
roc_curve(truth = Attrition, .pred_yes) %>%
# Plot the ROC curve
autoplot()
# Create an ROC curve
employee_final_fit %>%
# Collect predictions
collect_predictions() %>%
# Calculate ROC curve metrics
roc_curve(truth = Attrition, .pred_Yes) %>%
# Plot the ROC curve
autoplot()
# Create an ROC curve
employee_final_fit %>%
# Collect predictions
collect_predictions() %>%
# Calculate ROC curve metrics
roc_curve(truth = Attrition, .pred_No) %>%
# Plot the ROC curve
autoplot()
prep_predictions_df %>%
roc_curve(truth = Attrition, .pred_No) %>%
autoplot()
# Calculate metrics
last_fit_metrics(prep_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
dt_predictions_df <- employee_final_fit %>%
collect_predictions()
dt_predictions_df
# Calculate metrics
last_fit_metrics(dt_predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# Calculate metrics
last_fit_metrics(predictions_df,
truth = Attrition,
estimate = .pred_class,
.pred_No)
# Explore model performance for logistic regression
logistic_rs_results %>%
group_by(.metric) %>%
summarize(min = min(.estimate),
median = median(.estimate),
max = max(.estimate))
?collect_predictions
# TIDYMODELS WORKFLOW - REGRESSION ----
#
# 1.0 LOAD LIBRARIES ----
library(tidymodels)
library(modeldata)
?collect_predictions
